\documentclass[xcolor=dvipsnames,hyperref={pdfpagelabels=false}]{beamer}

\usetheme{Boadilla}

\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\be}{\begin{enumerate}}
\newcommand{\ee}{\end{enumerate}}
\newcommand{\bc}{\begin{center}}
\newcommand{\ec}{\end{center}}
\newcommand{\bd}{\begin{description}}
\newcommand{\ed}{\end{description}}
\newcommand{\I}{\item}
\newcommand{\f}{\frame}
\newcommand{\ft}{\frametitle}

\title{Offline Software Overview}
\subtitle{GlueX Collaboration Meeting}
\author[Mark Ito]{Mark M.\ Ito}
\date{October 3, 2014}
\institute[JLab]{Jefferson Lab}

\begin{document}

\f{\titlepage}

\f{\ft{Outline}
\be
\I Tagger Reconstruction and Global Event Timing
\I Data Challenge 3
\I Miscellaneous Topics since May 2014
\I Other Talks at This Meeting
\ee
}

\f{
\ft{Tagger Reconstruction and Global Event Timing}
\bi
\I Richard Jones introduced a random global time offset to all events, consistent with the 500 MHz RF time structure. This would simulate the real-life uncertainty due to event-to-event trigger latency variations and the time-bin effect from 250 MHz clock. Before all events are analyzed as if the true RF bucket is known, a priori. Also the true beam photon energy is also assumed in the analysis. 
\I HDDM Calls: Conversion to C++ API: All invocations of the HDDM API have been upgraded to use the C++ version rather than the old C version. This change comes in many places in the sim-recon tree. GEANT-3-based code (HDGeant) was exempted.
\I HDDM Integrity Checks: The HDDM library now supports "integrity checks" where a cyclic redundancy check (CRC) code is computed event-by-event and is written with the event. Downstream programs can check that incoming data has not been corrupted.
\I HDDM\_s Changes: Simulation output has been changed to rationalize data storate in two areas: (1) the mix of truth and hit information and (2) the detector component hierarchy.
\I Tagger Analysis: CCDB tagger tables have been rationalized and new C++ classes introduced in sim-recon to accommodate the new scheme. The start counter was used as a model for the low-level hit classes in the DAQ plug-in. There were some modifications needed to HDGeant (GEANT3) code to write the new classes.
\I Analysis Library Changes: Paul will need to change the analysis library to deal with the ambiguity of the "correct" tagger hit. For now he will use the factory tag for the tagger to get the true tagger hit. That makes things more or less as things were before. Once the merge onto the trunk is done, he will implement the necessary changes.
\ei
}

\frame{\ft{List of Changed Files}
\input file_list_merge_1.tex
}

\frame{
\input file_list_merge_2.tex
}

\frame{
\input file_list_merge_3.tex
}

\frame{
\input file_list_merge_4.tex
}

\frame{
\input file_list_merge_5.tex
}

\frame{
\input file_list_merge_6.tex
}

\frame{
\input file_list_merge_7.tex
}

\frame{
\input file_list_merge_8.tex
}

\f{
\ft{Data Challenge 3}
\bi
\I Original goals:
  \be
  \I process fake raw data resident in the tape library
  \I render the data in EVIO format
  \I perform more efficient generation of the electromagnetic background
  \I use the Geant4 version of HDGeant
  \I incorporate new code for obtaining constants from the CCDB
  \ee
\I Dropped \#3, \#4, \#5 during summer
\I Dropped \#1, \#2 in September
\I Other large scale simulation tasks superceded: commissioning geometry, tagger hall
\ei
}

\f{\ft{Miscellaneous Topics I}
\bi
\I David Lawrence produced new field maps for studies of effects at lower field.
\I Sean Dobbs has the backend database code for EventStore all done.
\I David changed CCDB so that one-dimensional arrays treated the same whether they are single column or single row.
\I Simon has changed the code to get the parameter for the minimum number of hits on a track candidate from a JANA configuration parameter.
\I David has finished implementing chain from HDDM simulation output to EVIO format to JANA-based reconstruction.
\I Will Levine has observed a late tail in the BCAL time distributions for pions and not photons.
\I David implement use of a MD5 check-sum that is generated and downloaded along with each resource file to check file integrity.
\I Haswell CPU Testing: David did bench-marking test with a demo machine that SciComp had on loan for this purpose. This is to inform future purchase for the Farm.
\I David changed the HDDS build system from GNU Make to SCons.
\I Gxtwist is a stand-alone simulation of the tagger hall. Richard has updated the geometry based on the latest drawings. He has also added reality to the radiator with separate positions for the diamond and the amorphous radiators. 
\I Re-Creating tracks with new mass hypotheses during analysis (post-reconstruction). This can be very time-consuming. Simon worked on providing a full set of mass hypotheses to the REST file.
\I Comparing Simulated HDDM and EVIO Files: Sean has done comparisons between hit information between simulation native output (HDDM format) and EVIO data derived from same using the new trunk from Richard.
\ei
}

\f{
\ft{Other Talks at This Meeting}
\bi
\I Offline Data Quality Monitoring: see Paul Mattione's talk
\I Simulating the Commissioning Detector Configuration: see Sean Dobb's talk
\I Analysis of Six Final States Using Data Challenge 2 MC: see Ryan Mitchell's talk (Physics Session)
\ei
}

\end{document}
