\documentclass[xcolor=dvipsnames,hyperref={pdfpagelabels=false}]{beamer}

\usetheme{AnnArbor}

\let\Tiny=\tiny

\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\be}{\begin{enumerate}}
\newcommand{\ee}{\end{enumerate}}
\newcommand{\bc}{\begin{center}}
\newcommand{\ec}{\end{center}}
\newcommand{\I}{\item}
\newcommand{\f}{\frame}
\newcommand{\ft}{\frametitle}

\title{Hall D Software Overview}
\subtitle{12 GeV Software Review}
\author[Mark Ito]{Mark M.\ Ito}
\date{June 7, 2012}
\institute[JLab]{Jefferson Lab}

\begin{document}

\f{\titlepage}

\f{
\ft{Outline}
\be
\I{Data/Analysis Flow}
\I{Manpower}
\I{Computing Resource Requirements}
\I{Calibration and Alignment}
\I{Amplitude Analysis}
\I{Reconstruction Development}
\I{Software Management}
\I{Conclusions}
\ee
}

% 1 Data/Analysis Flow Slide A variation on the above slide
% emphasizing what is done and what needs to be done. 120s (1090s)

\section{Data/Analysis Flow}

\frame<1>[label=flow-diagram]{
\ft{Flow Diagram}
\small
\begin{columns}[c]
\begin{column}{1.0in}
\bi
\I<alert@1> boxes: processors
\I<alert@2> ovals: data formats
\I<alert@3> punch cards: databases
\ei
\end{column}
\begin{column}{3.0in}
\includegraphics[width=3.0in]{overview_diagram.png}
\end{column}
\end{columns}
}

\f{
\ft{Processors}
\bi
\I Simulation/Digitization
   \bi
   \I GEANT3-based
   \I Geometry XML-driven (not coded)
      \bi
      \I Hall D Detector Definition language (HDDS)
      \ei
   \I experimental resolution introduced in separate process (hdsmear)
   \I mature
   \ei
\I Reconstruction
   \bi
   \I based on Jana framework
   \bi
   \I C++
   \I multi-threaded
   \I factory model
   \I data available from framework as STL vectors of objects ({\it e.\ g.}, hits, tracks, clusters)
   \ei
   \I framework fully functional
   \I factories undergoing constant revision
   \ei
\ei
}

\subsection{Geant4}

\frame<1-2>[label=geant4]{
\ft{Geant4 Conversion}
\bi
\I<alert@1> Conversion has started as a background task
\I<alert@2> Geometry from same HDDS files as for Geant3 implementation
\I<alert@3> Hit generation: no new algorithms, core C code
  \bi
  \I wrapped for FORTRAN for Geant3 implementation
  \I wrapped for C++ for Geant4 implementation
  \ei
\ei
}

\f{
\bc
\includegraphics[width=3.5in]{gluex_global.jpg}
\ec
}

\f{
\bc
\includegraphics[width=3.5in]{cutaway.jpg}
\ec
}

\f{
\bc
\includegraphics[width=3.5in]{cutaway_zoom.jpg}
\ec
}

\againframe<3>{geant4}

\againframe<2>{flow-diagram}

\f{
\ft{Serialized data formats}
\bi
\I Raw data
   \bi
   \I EVIO: CEBAF Online Data Acquisition (CODA) format
   \ei
\I Simulated data
   \bi
   \I HDDM: Hall D Data Model
   \I XML-like
   \I compressed
   \I each file contains complete description of elements, attributes
      \bi
      \I element/attribute names
      \I data types
      \I multiplicity info (exacly one, at least one, many)
      \ei
   \I support utilities for conversion
   \ei
\I Reconstructed data
   \bi
   \I HDDM
   \I others possible
   \ei
\ei
}

\againframe<3>{flow-diagram}

\f{
\ft{Databases}
\bi
\I Calibration Constants
   \bi
   \I relational database
   \I standard look up by run
   \I hierarchical calibration type structure
   \I history kept, previous versions selectable at run time
   \I branches/private/tagged versions supported (with history)
   \I developed, in beta (Hall B is using it too)
   \ei
\I Other Database Applications
   \bi
   \I Online Conditions/Parameters
   \I Translation Tables
   \I DST
   \ei
\ei
}

\section{Manpower}

% 2 Manpower Estimates A slide showing the broken out tasks with \%
% complete, manpower needed to complete and names of people with
% institutions that are responsible for the tasks. Conclusion that at
% least at the present, we appear to have sufficient manpower to
% complete the tasks in the time given. 120s (1210s)

\f{
\ft{Manpower Requirements and Project Progress}
\small
\begin{columns}[c]
\begin{column}{1.5in}
   \bi
   \I required manpower for various tasks estimated
   \I manpower already expended has been estimated
   \I assignment of tasks to individuals
   \ei
\end{column}
\begin{column}{2.0in}
\includegraphics[width=2.0in]{OfflineComputingActivities2012.png}
\end{column}
\end{columns}
}

\f{
\ft{Manpower Requirements, Example Items}
\includegraphics[width=4.75in]{OfflineComputingActivities2012Zoom.png}
}

\f{
\ft{Manpower Resources}
\includegraphics[width=2.5in]{manpower_survey_raw.png}
\small
\bi
\I collaboration has been surveyed
\I manpower resources available for software infrastructure tabulated
\I differentiated by type (grad student, post-doc, faculty,...)
\I availability year-by-year shown
\ei
}

\f{
\ft{Manpower Resources}

\includegraphics[width=4.5in]{manpower_survey_graphs.png}

Conclusion: match with level of effort required to finish requirements
}

% 3 Software Management A slide showing how the Offline group is
% organized, and how it interacts with the other groups involved in
% related tasks. 60s (1270s)

%\f{
%\ft{Software Management}
%\includegraphics[height=3.0in]{org_chart_slide.png}
%}

\section{Computing Resource Requirements}

% 6 Data Analysis Model Lay out the model for analysis of GlueX
% data. Raw data on tape/disk at Jefferson Lab. DST’s produced at
% Jefferson Lab, on Tape/Disk. MiniDSTs produced at Jefferson Lab and
% then both analyzed on site and moved off site utilizing
% grid-ftp. 120s (1630s)

% 7 Simulation Lay out the model for GlueX simulation. Production both
% at Jefferson Lab and at remote sites. Simulation will produce
% MiniDSTs that will need to be moved. All other data is likely
% flushed. What are the expecte resources in outside sites? 120s
% (1760s)

\f{
\ft{Data Analysis Model}
   \bi
   \I From detector to CODA EMU's to monitoring farm to online cache disk
   \I Over network to Tape Library in Computer Center
   \I Reconstruction on JLab batch farm, reduction of volume by factor of 10
   \I Reconstructed data written to Tape Library: some fraction live on disk
   \I DST's in several streams produced: large fraction live on disk
   \I Similiar scenario for Monte Carlo except ``raw'' Monte Carlo not kept
   \I Analysis engines access this data:
      \bi
      \I JLab batch farm
      \I Individual work stations
      \I Collaborating institutions
      \I Grid resources
      \I PWA resources
      \ei
   \ei
}

% 4 Data/Compute Model A slide based on Mark’s spread sheet showing
% the way that we estimate data volumes and CPU needs. Discuss phase
% I, II and III. 120s (1390s)

\f{
\ft{Data/Computing Model}

Assumptions:
\bi
   \I 20 kHz off detector
   \I 15 kB events
   \I run 35 weeks year, 50\% running efficiency
   \I 130 ms to reconstruct an event (measured)
   \I 5\% of data to calibrate
   \I 2 Monte Carlo events per data event
   \I 67 ms to generate Monte Carlo events (reconstruction time comparable to data)
   \I repetition factor: 2
   \I Other loads:
      \bi
      \I skims/mini-DST production
      \I physics analysis
      \I partial wave analysis
      \ei
\ei

}

\f{\ft{Summary of Requirements}
\bc
\begin{tabular}{|l|r|r|r|}
\hline
Process & CPU (kCores) & Disk (TB) & Tape (PB/y)\\
\hline
Raw Data & -- & -- & 3.2 \\
Calibration & 0.09 & -- & 0.06 \\
Reconstruction & 1.8 & -- & 1.3 \\
Streaming & 0.9 & -- & 0.6 \\
Analysis & 0.9 & 1000 & -- \\
Simulation & 5.4 & -- & 2.5 \\
\hline
Total & 9 & 1000 & 8 \\
\hline
\end{tabular}
\ec
}


% 8 Open Science Grid Discuss that GlueX is a virtual organization in
% the OSG. Some resources from outside are committed to the grid. 120s
% (1890s)

\frame<1>[label=osg]{
\ft{Open Science Grid}

\bi
\I<alert@1> Have established GlueX VO with the OSG
\I<alert@2> Nodes from UConn have been contributed
\I<alert@3> Significant analysis has been performed using the grid ($3\pi$ analysis)
\I<alert@4> Use has roughly matched contribution
\I<alert@5> Grid tools have been installed at JLab (no significant use yet)
\I<alert@6> Plan to use Grid Storage Resource Manager (SRM) to move data on and off Lab site
\I<alert@7> Plan to use Grid compute resources to augment those at JLab
   \bi
   \I Monte Carlo generation and reconstruction
   \I Possible to have quick turn-around on specific tasks
   \ei
\ei
}

\f{
\bc
\includegraphics[width=3.5in]{osg_total_usage.png}
\ec
}

\againframe<2>{osg}

\f{
\bc
\includegraphics[width=3.5in]{osg_uconn_usage.png}
\ec
}

\againframe<3>{osg}

\f{
\bc
\includegraphics[width=3.5in]{osg_gluex_usage.png}
\ec
}

\againframe<4-7>{osg}

\f{
\ft{Expected Non-JLab Resources}
\includegraphics[width=4.5in]{ComputingResourcesZoom.png}
\bi
\I Have compiled info on compute farms at collaborating institutions
\I Only UConn grid enabled
\ei
}

\section{Calibration and Alignment}

% 5 Calibration/Alignment What needs to be calibrated and how will it
% be done? What has been done already? pi0 calibration of the FCAL,
% CDC prototype alignment and calibration, others? Beam tests? 120s
% (1510s)

\f{
\ft{Calibration/Alignment}
\bi
\I Developing plans for calibration
   \bi
   \I Each working group tasked to list methods, data requirements, compute requirements
   \I Examples:
      \bi
      \I $\pi^0$ calibration of forward calorimeter
      \I run plan for tracking chamber alignment
      \I time walk corrections for time-of-flight using plane-to-plane information
      \ei
   \ei
\I Not very advanced on this front; people are busy building detectors
\ei
}

\section{Amplitude Analysis}

% 9 Amplitude Analysis On GPUs 60s (1950s)

\f{
\ft{Amplitude Analysis on GPU's}

\bi
\I Calculation of log likelihoods for individual events
   \bi
   \I independent for each events
   \I computationally expensive
   \I not branch intensive
   \I result is small (in bytes)
   \I results are to be summed
   \ei
\I Technique being used by many experiments
\I One of leading implementations developed by GlueX collaborator: AmpTools
\I Large reduction in scale of compute task
\I Infrastructure will evolve
\I Used in $3\pi$ analysis
\ei
}

% 10 Data Challenge What sort of data challenge do we need? When? 60s
% (2000s)

\f{
\ft{Data Challenges}

\bi
\I Plans only
\I Simulate raw data to DST chain on a large scale
   \bi
   \I Need to develop job management tools
   \ei
\I Establish viability of data transfer capability, to and from JLab
   \bi
   \I Need to establish data management tools (meta-data catalog)
   \ei
\ei
}

\section{Reconstruction Development}

\f{
\ft{Reconstruction: Efficiency and Resolution}
\bi
   \I Major area of effort right now
   \I Track reconstruction in a non-uniform magnetic field
      \bi
      \I curling tracks
      \I areas of reduced efficiency/resolution
      \I reconstruction speed
      \ei
   \I Photon reconstruction
      \bi
      \I split-offs
      \I merged clusters
      \I effort to lower thresholds
      \I hadronic contamination
      \ei
\ei
}

\section{Management}

\f{
\ft{Software Management Tools}
\bi
\I Source code version control: Subversion
\I Regular tagged releases of reconstruction software: about every 6 weeks
\I Nightly builds of reconstruction software
   \bi
   \I all Lab-supported Linux flavors
   \I Doxygen documentation generated
   \ei
\I Semi-weekly reconstruction tests
   \bi
   \I single-charged particles
   \I multi-track, multi-photon events
   \I histograms generated, archived
   \ei
\I Mantis bug tracker for issue tracking
\I Communication
   \bi
   \I email list, wiki, note repository, ReadyTalk, ESNet, EVO
   %\I no Facebook or Twitter...yet
   \ei
\ei
}

\f{
\ft{Software Milestones}
\begin{tabular}{rp{3.3in}l}
& \bf Task & \bf Date \\
1 & deploy calibration database & 2012-07-15 \\
2 & deploy translation database & 2012-09-01 \\
3 & complete raw data format specification & 2012-10-01 \\
4 & complete specification of reconstructed data format & 2012-10-15 \\
5 & data challenge: simulated raw data to reconstructed data (one day at $10^7~\gamma/s$) & 2012-12-01 \\
6 & complete DST writer & 2013-02-01 \\
7 & create DST data samples from data challenge events & 2013-03-01 \\
8 & amplitude analysis & 2013-04-01 \\
9 & documentation complete & 2013-06-15 \\
10 & full software chain & 2013-08-15 \\
\end{tabular}
}

\section{Conclusions}

% 11 Summary/Conclusion Summarize where we are and where we are
% going. List of what still needs to be done? Contingencies. 60s
% (2060s)

\begin{frame}[fragile]
\ft{Summary/Conclusions}
Accomplishments
\bi
\I End-to-end solution for reconstruction, simlulation, DST-generation in hand
   \bi
   \I neutral and charged particles simulated and reconstructed
   \ei
\I Amplitude analysis capability demonstrated
   \bi
   \I GPU method developed
   \I $\gamma p \rightarrow n\pi^+\pi^+\pi^-$
   \I $\gamma p \rightarrow Xp$, $X \rightarrow b_1\pi$, $b_1 \rightarrow \omega\pi$, $\omega\rightarrow\pi^+\pi^-\pi^0$
   \ei
\ei
To Do
\bi
\I Calibration
\I Large-scale data challenges
\I Reconstruction efficiency and resolution
\ei

\vskip 0.5in
\hrule
\tiny
\begin{verbatim}
$Id$
\end{verbatim}
\end{frame}


\end{document}
